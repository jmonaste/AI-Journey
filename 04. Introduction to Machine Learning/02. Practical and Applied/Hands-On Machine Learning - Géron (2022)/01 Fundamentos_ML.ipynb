{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: Los Fundamentos del Machine Learning\n",
    "\n",
    "Este notebook unifica todo el contenido de los fundamentos del Machine Learning basado en el libro \"Hands-On Machine Learning\" de AurÃ©lien GÃ©ron (2022).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. El Panorama del Aprendizaje AutomÃ¡tico\n",
    "\n",
    "## ðŸ“§ IntroducciÃ³n\n",
    "\n",
    "La primera aplicaciÃ³n de ML que se volviÃ³ mainstream fue el **filtro de spam en el correo electrÃ³nico**.\n",
    "\n",
    "Este capÃ­tulo responde quÃ© es el ML y por quÃ© usarlo, explorando las principales distinciones:\n",
    "\n",
    "- **Aprendizaje supervisado vs no supervisado**\n",
    "- **Aprendizaje online vs por lotes (batch)**\n",
    "- **Aprendizaje basado en instancias vs basado en modelos**\n",
    "\n",
    "TambiÃ©n aborda los desafÃ­os de **evaluar y ajustar (fine-tune)** los sistemas de ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning: DefiniciÃ³n y Aplicabilidad\n",
    "\n",
    "### ðŸ¤– DefiniciÃ³n\n",
    "\n",
    "El machine learning se define como **el campo de estudio que otorga a los ordenadores la capacidad de aprender sin ser explÃ­citamente programados**.\n",
    "\n",
    "El sistema aprende utilizando un **training set** compuesto por **training instances** (muestras), y su rendimiento se evalÃºa mediante mÃ©tricas como **accuracy** o **precision**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ’¡ Â¿CuÃ¡ndo usar ML?\n",
    "\n",
    "El ML resulta especialmente adecuado para Ã¡reas donde el enfoque tradicional es demasiado complejo o no existe un algoritmo conocido, siendo la mejor soluciÃ³n actual escribir algoritmos que aprendan por sÃ­ mismos mediante numerosos ejemplos.\n",
    "\n",
    "AdemÃ¡s, la aplicaciÃ³n de tÃ©cnicas de ML en grandes volÃºmenes de datos permite descubrir patrones no evidentes inicialmente, proceso conocido como **data mining**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“‹ Resumen: ML es apropiado para\n",
    "\n",
    "- âœ… Problemas que requieren **mÃºltiples reglas** en soluciones existentes\n",
    "- âœ… Problemas complejos **sin soluciÃ³n tradicional** adecuada\n",
    "- âœ… Entornos **fluctuantes**\n",
    "- âœ… Cuando se necesita **extraer informaciÃ³n** de problemas complejos con grandes cantidades de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Sistemas de Machine Learning\n",
    "\n",
    "### ðŸ“Š ClasificaciÃ³n Principal\n",
    "\n",
    "Los sistemas de ML se clasifican segÃºn **tres criterios principales**:\n",
    "\n",
    "1. **SupervisiÃ³n humana**: supervised, unsupervised, semisupervised, reinforcement learning\n",
    "2. **Aprendizaje incremental**: online vs batch\n",
    "3. **Estrategia de generalizaciÃ³n**: instance-based vs model-based learning\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ·ï¸ Supervised vs Unsupervised\n",
    "\n",
    "#### ðŸŽ“ Aprendizaje Supervisado\n",
    "\n",
    "Los datos de entrenamiento incluyen la soluciÃ³n denominada **\"label\"**.\n",
    "\n",
    "##### Tareas TÃ­picas\n",
    "\n",
    "- **ClasificaciÃ³n** (como filtros de spam)\n",
    "- **RegresiÃ³n** (como predecir precios de coches)\n",
    "\n",
    "> âš ï¸ **Nota importante:** Algunos algoritmos de regresiÃ³n pueden usarse para clasificaciÃ³n y viceversa.\n",
    "\n",
    "##### Algoritmos MÃ¡s Importantes\n",
    "\n",
    "- **k-nearest neighbors**\n",
    "- **Linear regression**\n",
    "- **Logistic regression**\n",
    "- **Support Vector Machines (SVMs)**\n",
    "- **Decision trees and random forests**\n",
    "- **Neural networks** (aunque algunas arquitecturas pueden ser no supervisadas o semisupervisadas)\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ” Aprendizaje No Supervisado (Unsupervised Learning)\n",
    "\n",
    "En el aprendizaje no supervisado **no hay etiquetas**, los datos de entrenamiento no estÃ¡n etiquetados y el sistema intenta aprender **\"sin un profesor\"**.\n",
    "\n",
    "##### ðŸ“¦ Clustering\n",
    "\n",
    "- **K-means**\n",
    "- **Hierarchical Cluster Analysis (HCA)**\n",
    "- **Expectation Maximization**\n",
    "\n",
    "##### ðŸ“Š VisualizaciÃ³n y ReducciÃ³n de Dimensionalidad\n",
    "\n",
    "- **Principal Component Analysis (PCA)**\n",
    "- **Kernel PCA**\n",
    "- **Locally-Linear Embedding (LLE)**\n",
    "- **t-Distributed Stochastic Neighbor Embedding (t-SNE)**\n",
    "\n",
    "##### ðŸ”— Association Rule Learning\n",
    "\n",
    "- **Apriori**\n",
    "- **Eclat**\n",
    "\n",
    "> ðŸ’¡ **Buena prÃ¡ctica:** Siempre es recomendable aplicar reducciÃ³n de dimensionalidad a los datos de entrenamiento sin perder demasiada informaciÃ³n.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸŽ¯ Aprendizaje Semisupervisado\n",
    "\n",
    "Algunos algoritmos pueden trabajar con **datasets parcialmente etiquetados**, constituyendo el aprendizaje semisupervisado.\n",
    "\n",
    "##### Ejemplo PrÃ¡ctico\n",
    "\n",
    "**Google Photos** agrupa fotos por personas que aparecen en ellas y solicita al usuario que las etiquete.\n",
    "\n",
    "##### ComposiciÃ³n\n",
    "\n",
    "La mayorÃ­a de algoritmos semisupervisados son **combinaciones de algoritmos no supervisados y supervisados**.\n",
    "\n",
    "##### Deep Belief Networks (DBNs)\n",
    "\n",
    "Un caso especÃ­fico son las **Deep Belief Networks (DBNs)**, que se basan en componentes no supervisados llamados **Restricted Boltzmann Machines (RBMs)** apilados.\n",
    "\n",
    "**Proceso de entrenamiento:**\n",
    "1. Los RBMs se entrenan secuencialmente de manera no supervisada\n",
    "2. Todo el sistema se ajusta finamente (fine-tuned) utilizando tÃ©cnicas de aprendizaje supervisado\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ¤– Aprendizaje por Refuerzo (Reinforcement Learning)\n",
    "\n",
    "En el aprendizaje por refuerzo, el sistema de aprendizaje se denomina **agente** y puede:\n",
    "\n",
    "- ðŸ‘ï¸ Observar el entorno\n",
    "- âš¡ Seleccionar y ejecutar acciones\n",
    "- ðŸŽ Obtener recompensas a cambio (o penalizaciones en forma de recompensas negativas)\n",
    "\n",
    "##### Policy\n",
    "\n",
    "El agente debe aprender por sÃ­ mismo cuÃ¡l es la mejor estrategia, llamada **policy**, para obtener la mayor recompensa a lo largo del tiempo.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”„ Batch and Online Learning\n",
    "\n",
    "#### ðŸ“‹ Criterio de ClasificaciÃ³n\n",
    "\n",
    "Otro criterio para clasificar los sistemas de ML es si el sistema puede aprender incrementalmente desde el flujo (**stream**) de datos de entrada o no.\n",
    "\n",
    "Esta distinciÃ³n establece la diferencia entre:\n",
    "- **Aprendizaje online**: El modelo puede actualizarse continuamente con nuevos datos\n",
    "- **Aprendizaje batch**: Requiere entrenar desde cero con todo el conjunto de datos disponible\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ“¦ Batch Learning (Aprendizaje por Lotes)\n",
    "\n",
    "En el batch learning, el sistema **no puede aprender incrementalmente** y debe ser reentrenado utilizando todos los datos disponibles.\n",
    "\n",
    "##### CaracterÃ­sticas\n",
    "\n",
    "- Se realiza **offline** porque requiere mucho tiempo y recursos computacionales\n",
    "- Por esta razÃ³n se denomina **offline training**\n",
    "- El proceso puede automatizarse (entrenar, evaluar, lanzar)\n",
    "\n",
    "##### Limitaciones\n",
    "\n",
    "> âš ï¸ **Problema principal:** El entrenamiento sobre nuevos datos junto con los antiguos puede durar horas, lo que representa una limitaciÃ³n significativa cuando se necesita actualizar el modelo con frecuencia.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ”„ Online Learning\n",
    "\n",
    "En el online learning, el modelo se entrena de manera **incremental** alimentÃ¡ndolo con instancias de datos secuenciales individualmente o en pequeÃ±os grupos llamados **mini-batches**.\n",
    "\n",
    "##### Ventajas\n",
    "\n",
    "- âš¡ Cada paso de aprendizaje es **rÃ¡pido y econÃ³mico**\n",
    "- ðŸ” El sistema aprende sobre la marcha con nuevos datos segÃºn van llegando\n",
    "- ðŸ’» Es una buena opciÃ³n cuando se tienen **recursos limitados**\n",
    "\n",
    "##### Out-of-Core Learning\n",
    "\n",
    "Los algoritmos de aprendizaje online tambiÃ©n pueden usarse para entrenar sistemas sobre **grandes datasets que no caben en la memoria** de una mÃ¡quina, proceso conocido como **out-of-core learning**.\n",
    "\n",
    "##### Learning Rate\n",
    "\n",
    "Un parÃ¡metro importante es el **learning rate**, que determina quÃ© tan rÃ¡pido se adapta el sistema a los cambios.\n",
    "\n",
    "##### âš ï¸ DesafÃ­os\n",
    "\n",
    "Uno de los principales retos es evitar que el rendimiento decaiga cuando entran **datos de mala calidad** al sistema.\n",
    "\n",
    "> ðŸ’¡ **SoluciÃ³n:** Para minimizar este riesgo, es necesario monitorizar tanto el sistema como su entrada de datos.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ Instance-Based vs Model-Based Learning\n",
    "\n",
    "#### Objetivo de la GeneralizaciÃ³n\n",
    "\n",
    "Otra manera de categorizar sistemas de ML es segÃºn **cÃ³mo generalizan**, ya que el objetivo final es **predecir correctamente nuevas instancias**.\n",
    "\n",
    "Existen **dos enfoques principales** de generalizaciÃ³n:\n",
    "- **Instance-based learning**\n",
    "- **Model-based learning**\n",
    "\n",
    "Cada uno con estrategias diferentes para hacer predicciones sobre datos no vistos previamente.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ’¾ Instance-Based Learning\n",
    "\n",
    "Posiblemente la forma mÃ¡s trivial de aprendizaje es **aprender de memoria**.\n",
    "\n",
    "##### Ejemplo: ClasificaciÃ³n de Spam\n",
    "\n",
    "Por ejemplo, clasificar emails como spam cuando son idÃ©nticos a correos ya etiquetados como spam. No es la peor soluciÃ³n, pero ciertamente no es la mejor.\n",
    "\n",
    "##### Medida de Similitud\n",
    "\n",
    "Se puede usar una **medida de similitud** para etiquetar correos parecidos al spam.\n",
    "\n",
    "Una forma bÃ¡sica de similitud en el caso del spam es **contar el nÃºmero de palabras que tienen en comÃºn**.\n",
    "\n",
    "##### DefiniciÃ³n\n",
    "\n",
    "> ðŸ“Œ **Instance-based learning:** El sistema aprende los ejemplos de memoria y luego generaliza a nuevos casos usando medidas de similitud.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ”¬ Model-Based Learning\n",
    "\n",
    "Otra forma de generalizar a partir de un conjunto de ejemplos es **construir un modelo** de esos ejemplos y luego usar dicho modelo para hacer predicciones.\n",
    "\n",
    "##### Ejemplo: SatisfacciÃ³n de Vida vs GDP\n",
    "\n",
    "Si descargamos datos de GDP per cÃ¡pita de paÃ­ses y el Ã­ndice de satisfacciÃ³n de vida:\n",
    "\n",
    "1. Hacemos un grÃ¡fico\n",
    "2. Observamos una especie de relaciÃ³n lineal\n",
    "3. Decidimos modelar la satisfacciÃ³n de vida como una funciÃ³n lineal del GDP per cÃ¡pita\n",
    "\n",
    "##### Model Selection\n",
    "\n",
    "> ðŸ“Š **Model Selection:** Hemos seleccionado un modelo lineal de la satisfacciÃ³n de vida con un solo atributo, el GDP per cÃ¡pita.\n",
    "\n",
    "##### SelecciÃ³n de ParÃ¡metros\n",
    "\n",
    "Antes de usar el modelo, debemos seleccionar algunos **parÃ¡metros** para la funciÃ³n lineal.\n",
    "\n",
    "Para elegir estos parÃ¡metros, debemos definir una **medida de rendimiento**.\n",
    "\n",
    "##### Funciones de EvaluaciÃ³n\n",
    "\n",
    "Podemos definir:\n",
    "\n",
    "- **Utility function** (o fitness function): mide quÃ© tan **bueno** es el modelo\n",
    "- **FunciÃ³n de costo**: mide cuÃ¡n **malo** es\n",
    "\n",
    "##### RegresiÃ³n Lineal\n",
    "\n",
    "Para problemas de **regresiÃ³n lineal**, se usa tÃ­picamente una funciÃ³n de costo que mide la distancia entre:\n",
    "- La predicciÃ³n del modelo lineal\n",
    "- Las muestras de ejemplo\n",
    "\n",
    "> ðŸŽ¯ **Objetivo:** Minimizar esta distancia, y aquÃ­ es donde el **algoritmo de regresiÃ³n lineal** entra en escena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principales desafÃ­os del ML\n",
    "\n",
    "### Datos de Entrenamiento Insuficientes\n",
    "\n",
    "Para que un niÃ±o pequeÃ±o aprenda quÃ© es una manzana, basta con que le seÃ±ales una o dos manzanas (y posiblemente un contraejemplo, como una pera). Para la mayorÃ­a de tareas de ML, esto no es suficiente; se necesitan miles de ejemplos, y para problemas complejos como reconocimiento de imÃ¡genes o reconocimiento de voz se pueden necesitar millones de ejemplos.\n",
    "\n",
    "### Datos de Entrenamiento No Representativos\n",
    "\n",
    "Para generalizar bien, es fundamental que los datos de entrenamiento sean representativos de los nuevos casos que queremos predecir. Si la muestra es demasiado pequeÃ±a, se tendrÃ¡ ruido de muestreo (datos no representativos por azar), pero incluso muestras grandes pueden ser no representativas si el mÃ©todo de muestreo es defectuoso. Esto se llama sesgo de muestreo.\n",
    "\n",
    "### Datos de Mala Calidad\n",
    "\n",
    "Si los datos de entrenamiento estÃ¡n llenos de errores, valores atÃ­picos y ruido (debido, por ejemplo, a mediciones de mala calidad), serÃ¡ mÃ¡s difÃ­cil para el sistema detectar los patrones subyacentes, por lo que es menos probable que el sistema funcione bien. Vale la pena el esfuerzo de limpiar los datos de entrenamiento.\n",
    "\n",
    "### CaracterÃ­sticas Irrelevantes\n",
    "\n",
    "Un sistema de ML solo puede aprender si los datos de entrenamiento contienen suficientes caracterÃ­sticas relevantes y pocas irrelevantes. Una parte crÃ­tica del Ã©xito de un proyecto de ML es encontrar un buen conjunto de caracterÃ­sticas para entrenar. Este proceso se llama ingenierÃ­a de caracterÃ­sticas (feature engineering) e involucra:\n",
    "\n",
    "- **SelecciÃ³n de caracterÃ­sticas**: seleccionar las caracterÃ­sticas mÃ¡s Ãºtiles para entrenar entre las existentes\n",
    "- **ExtracciÃ³n de caracterÃ­sticas**: combinar caracterÃ­sticas existentes para producir una mÃ¡s Ãºtil\n",
    "- **Crear nuevas caracterÃ­sticas**: recopilando nuevos datos\n",
    "\n",
    "### Sobreajuste de los Datos de Entrenamiento (Overfitting)\n",
    "\n",
    "Generalizar es el objetivo, pero tambiÃ©n es la principal dificultad. Cuando el modelo funciona bien en los datos de entrenamiento pero no generaliza bien a nuevos datos, se dice que el modelo estÃ¡ sobreajustado.\n",
    "\n",
    "El overfitting ocurre cuando el modelo es demasiado complejo en relaciÃ³n con la cantidad y el ruido de los datos de entrenamiento.\n",
    "\n",
    "**Soluciones:**\n",
    "- Simplificar el modelo seleccionando uno con menos parÃ¡metros\n",
    "- Reducir el nÃºmero de atributos en los datos de entrenamiento\n",
    "- Restringir el modelo (regularizaciÃ³n)\n",
    "- Recopilar mÃ¡s datos de entrenamiento\n",
    "- Reducir el ruido en los datos de entrenamiento\n",
    "\n",
    "### Subajuste de los Datos de Entrenamiento (Underfitting)\n",
    "\n",
    "El underfitting es lo opuesto al overfitting: ocurre cuando el modelo es demasiado simple para aprender la estructura subyacente de los datos.\n",
    "\n",
    "**Soluciones:**\n",
    "- Seleccionar un modelo mÃ¡s potente con mÃ¡s parÃ¡metros\n",
    "- Alimentar mejores caracterÃ­sticas al algoritmo de aprendizaje\n",
    "- Reducir las restricciones del modelo (reducir la regularizaciÃ³n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo PrÃ¡ctico: SatisfacciÃ³n de Vida vs GDP per CÃ¡pita\n",
    "\n",
    "Veamos un ejemplo que GerÃ³n muestra en su libro. Supongamos que queremos saber si el dinero hace felices a las personas.\n",
    "\n",
    "Para esto, vamos a descargar los datos del \"Ãndice para una Vida Mejor\" del sitio web de la OCDE y las estadÃ­sticas del Banco Mundial sobre el producto interior bruto (PIB) per cÃ¡pita. Luego unimos las tablas y las ordenamos por PIB per cÃ¡pita.\n",
    "\n",
    "* **OCDE**: OrganizaciÃ³n internacional que reÃºne paÃ­ses para mejorar sus polÃ­ticas econÃ³micas y sociales.\n",
    "* **Banco Mundial**: InstituciÃ³n que financia proyectos y apoya el desarrollo econÃ³mico de paÃ­ses.\n",
    "* **PIB / PIB per cÃ¡pita**: El PIB mide todo lo que produce un paÃ­s; el PIB per cÃ¡pita muestra cuÃ¡nto produce o gana, en promedio, cada persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request # urllib es un paquete de python que sirve para \"consultar en la web\", y request es un mÃ³dulo especÃ­fico dentro de esta librerÃ­a\n",
    "from pathlib import Path # pathlib es un mÃ³dulo estÃ¡ndar de Python que sirve para trabajar con rutas de archivos y directorios de forma mÃ¡s intuitiva que con cadenas de texto\n",
    "\n",
    "# Crea un objeto Path que representa la ruta ./datasets/lifesat.\n",
    "datapath = Path() / \"datasets\" / \"lifesat\"\n",
    "\n",
    "# Crea la carpeta datasets/lifesat.\n",
    "# parents=True â†’ crea todas las carpetas intermedias si no existen.\n",
    "# exist_ok=True â†’ no da error si la carpeta ya existe.\n",
    "datapath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define la URL base donde estÃ¡n los archivos que queremos descargar.\n",
    "# En este caso, el fichero estÃ¡ en el repositorio de GerÃ³n\n",
    "data_root = \"https://github.com/ageron/data/raw/main/\"\n",
    "\n",
    "# Itera sobre los nombres de los archivos que queremos descargar.\n",
    "# Vamos a descargar los dos archivos explicados antes\n",
    "for filename in (\"oecd_bli.csv\", \"gdp_per_capita.csv\"):\n",
    "\n",
    "    # Comprueba si el archivo ya existe en nuestra carpeta local. Si existe, no lo descarga otra vez.\n",
    "    if not (datapath / filename).is_file():\n",
    "\n",
    "        # Muestra un mensaje indicando quÃ© archivo se estÃ¡ descargando.\n",
    "        print(\"Downloading\", filename)\n",
    "\n",
    "        # Construye la URL completa del archivo a descargar.\n",
    "        url = data_root + \"lifesat/\" + filename\n",
    "\n",
    "        # Descarga el archivo desde la URL y lo guarda en la ruta local especificada.\n",
    "        urllib.request.urlretrieve(url, datapath / filename)\n",
    "\n",
    "# Para que este cÃ³digo funcione en Google Colab:\n",
    "# Las rutas de archivos no se crean automÃ¡ticamente, pero Path funciona igual.\n",
    "# Los archivos se guardan en la carpeta temporal de Colab (/content/ por defecto).\n",
    "# No necesitas instalar urllib ni pathlib, son parte de Python estÃ¡ndar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos los ficheros descargados, ahora podemos leerlos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la librerÃ­a pandas, que sirve para trabajar con datos en forma de tablas\n",
    "import pandas as pd\n",
    "\n",
    "# Leemos los archivos CSV que descargamos antes (estÃ¡n en la carpeta 'datasets/lifesat')\n",
    "# Cada archivo se convierte en una \"tabla\" (DataFrame) dentro de Python\n",
    "oecd_bli = pd.read_csv(datapath / \"oecd_bli.csv\")\n",
    "gdp_per_capita = pd.read_csv(datapath / \"gdp_per_capita.csv\")\n",
    "\n",
    "# Elegimos el aÃ±o con el que queremos trabajar\n",
    "gdp_year = 2020\n",
    "\n",
    "# Guardamos los nombres de las columnas que queremos usar mÃ¡s adelante\n",
    "gdppc_col = \"GDP per capita (USD)\"   # Producto Interno Bruto por persona (en dÃ³lares)\n",
    "lifesat_col = \"Life satisfaction\"    # Nivel de satisfacciÃ³n con la vida\n",
    "\n",
    "# Filtramos la tabla para quedarnos solo con los datos del aÃ±o 2020\n",
    "gdp_per_capita = gdp_per_capita[gdp_per_capita[\"Year\"] == gdp_year]\n",
    "\n",
    "# Eliminamos las columnas que no nos interesan (\"code\" y \"year\")\n",
    "# axis=1 indica que estamos borrando columnas (no filas)\n",
    "gdp_per_capita = gdp_per_capita.drop([\"Code\", \"Year\"], axis=1)\n",
    "\n",
    "# Cambiamos los nombres de las columnas para que sean mÃ¡s claros\n",
    "gdp_per_capita.columns = [\"Country\", gdppc_col]\n",
    "\n",
    "# Hacemos que la columna \"Country\" (paÃ­s) sea el Ã­ndice de la tabla\n",
    "# AsÃ­ cada fila estarÃ¡ identificada por el nombre del paÃ­s\n",
    "gdp_per_capita.set_index(\"Country\", inplace=True)\n",
    "\n",
    "# Mostramos las primeras filas de la tabla para ver cÃ³mo quedÃ³\n",
    "gdp_per_capita.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a preprocesar los datos del Ãndice para una Vida Mejor (OECD BLI) para quedarnos solo con la columna \"SatisfacciÃ³n con la vida\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos las filas del DataFrame para quedarnos solo con los datos\n",
    "# donde la columna \"INEQUALITY\" tiene el valor \"TOT\"\n",
    "# (\"TOT\" significa \"Total\", es decir, sin distinguir por gÃ©nero, edad u otros factores)\n",
    "oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"] == \"TOT\"]\n",
    "\n",
    "# Reorganizamos la tabla con pivot() para que:\n",
    "# - Cada paÃ­s quede en una fila (index=\"Country\")\n",
    "# - Cada tipo de indicador (por ejemplo, \"Life satisfaction\", \"Income\", etc.) sea una columna\n",
    "# - Los valores numÃ©ricos de esos indicadores estÃ©n en las celdas (values=\"Value\")\n",
    "oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
    "\n",
    "# Mostramos las primeras filas del nuevo DataFrame para comprobar el resultado\n",
    "oecd_bli.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora combinemos los datos de satisfacciÃ³n con la vida y de PIB per cÃ¡pita, quedÃ¡ndonos solo con las columnas PIB per cÃ¡pita y SatisfacciÃ³n con la vida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos (fusionamos) las dos tablas: oecd_bli y gdp_per_capita\n",
    "# La uniÃ³n se hace usando los Ã­ndices (en este caso, el nombre del paÃ­s)\n",
    "# Esto crea una nueva tabla con las columnas de ambas fuentes de datos\n",
    "full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,\n",
    "                              left_index=True, right_index=True)\n",
    "\n",
    "# Ordenamos las filas del DataFrame segÃºn la columna del PIB per cÃ¡pita\n",
    "# Esto facilita analizar la relaciÃ³n entre el PIB y la satisfacciÃ³n con la vida\n",
    "full_country_stats.sort_values(by=gdppc_col, inplace=True)\n",
    "\n",
    "# Nos quedamos Ãºnicamente con las columnas de interÃ©s:\n",
    "# \"PIB per cÃ¡pita\" y \"SatisfacciÃ³n con la vida\"\n",
    "full_country_stats = full_country_stats[[gdppc_col, lifesat_col]]\n",
    "\n",
    "# Mostramos las primeras filas del DataFrame resultante\n",
    "full_country_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ilustrar el riesgo de sobreajuste (overfitting), GerÃ³n utiliza solo una parte de los datos (todos los paÃ­ses con un PIB per cÃ¡pita entre min_gdp y max_gdp). MÃ¡s adelante, muestra los paÃ­ses que se habÃ­an omitido y demuestra que no siguen en absoluto la misma tendencia lineal.\n",
    "\n",
    "GerÃ³n emplea este ejemplo para mostrar cÃ³mo un modelo puede parecer muy preciso si se analiza solo con una parte limitada de los datos (por ejemplo, paÃ­ses con PIB medio). Sin embargo, cuando se incorporan los paÃ­ses que quedaron fuera (con PIB muy alto o muy bajo), la relaciÃ³n deja de ser lineal, evidenciando el problema del sobreajuste, que ocurre cuando un modelo se adapta demasiado a los datos de entrenamiento y no generaliza bien a nuevos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los lÃ­mites inferior y superior del PIB per cÃ¡pita\n",
    "# Solo queremos analizar los paÃ­ses cuyo PIB per cÃ¡pita estÃ© dentro de este rango\n",
    "min_gdp = 23_500\n",
    "max_gdp = 62_500\n",
    "\n",
    "# Filtramos la tabla para quedarnos Ãºnicamente con los paÃ­ses\n",
    "# que tienen un PIB per cÃ¡pita entre min_gdp y max_gdp (inclusive)\n",
    "# La condiciÃ³n usa el operador \"&\" (AND) para combinar ambos filtros\n",
    "country_stats = full_country_stats[\n",
    "    (full_country_stats[gdppc_col] >= min_gdp) &\n",
    "    (full_country_stats[gdppc_col] <= max_gdp)\n",
    "]\n",
    "\n",
    "# Mostramos las primeras filas del nuevo DataFrame con los paÃ­ses seleccionados\n",
    "country_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto serÃ­a recomendable guardar los resultados ya que nos ha costado algo de trabajo llegar a esta tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el DataFrame 'country_stats' en un archivo CSV llamado 'lifesat.csv'\n",
    "# Este archivo contiene solo los paÃ­ses dentro del rango de PIB per cÃ¡pita definido (min_gdp a max_gdp)\n",
    "country_stats.to_csv(datapath / \"lifesat.csv\")\n",
    "\n",
    "# Guardamos el DataFrame completo 'full_country_stats' en otro archivo CSV llamado 'lifesat_full.csv'\n",
    "# Este archivo incluye todos los paÃ­ses, sin aplicar ningÃºn filtro\n",
    "full_country_stats.to_csv(datapath / \"lifesat_full.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de continuar, vamos a crear una pequeÃ±a funciÃ³n auxiliar. El propÃ³sito de esta funciÃ³n auxiliar es facilitar la organizaciÃ³n y el guardado de figuras generadas con matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la clase Path del mÃ³dulo pathlib para trabajar con rutas de archivos de forma segura\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definimos la carpeta donde se guardarÃ¡n las figuras generadas\n",
    "# Se crea la ruta \"./images/fundamentals\"\n",
    "IMAGES_PATH = Path() / \"images\" / \"fundamentals\"\n",
    "\n",
    "# Creamos la carpeta (y todas las carpetas intermedias si no existen)\n",
    "# parents=True permite crear carpetas intermedias\n",
    "# exist_ok=True evita errores si la carpeta ya existe\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Definimos una funciÃ³n para guardar figuras de matplotlib de forma consistente\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    # Construimos la ruta completa del archivo donde se guardarÃ¡ la figura\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "\n",
    "    # Ajustamos automÃ¡ticamente los mÃ¡rgenes de la figura si tight_layout=True\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "\n",
    "    # Guardamos la figura en el archivo especificado\n",
    "    # fig_extension define el formato (png, pdf, etc.)\n",
    "    # resolution define los puntos por pulgada (dpi) de la imagen\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente cÃ³digo lo utiliza GerÃ³n para visualizar la relaciÃ³n entre el PIB per cÃ¡pita y la satisfacciÃ³n con la vida en diferentes paÃ­ses.\n",
    "Su objetivo es:\n",
    "\n",
    "1. Explorar visualmente los datos y comprobar si existe una tendencia (por ejemplo, que los paÃ­ses mÃ¡s ricos tienden a tener mayor satisfacciÃ³n).\n",
    "2. Destacar algunos casos concretos (como TurquÃ­a, Dinamarca o EE. UU.) para mostrar que, aunque hay una tendencia general, no todos los paÃ­ses siguen exactamente la misma relaciÃ³n lineal.\n",
    "3. Preparar el terreno para introducir el concepto de modelos predictivos y sobreajuste: cÃ³mo los modelos pueden captar una tendencia aparente en una parte de los datos, pero fallar cuando se observan todos los casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un grÃ¡fico de dispersiÃ³n (scatter plot) para visualizar los datos\n",
    "# En el eje X se representa el PIB per cÃ¡pita (gdppc_col)\n",
    "# En el eje Y se representa la satisfacciÃ³n con la vida (lifesat_col)\n",
    "# figsize define el tamaÃ±o del grÃ¡fico, y grid=True activa la cuadrÃ­cula.\n",
    "# Puedes jugar con estos valores para ver cÃ³mo afectan a la presentaciÃ³n del grÃ¡fico\n",
    "country_stats.plot(kind='scatter', figsize=(6, 3), grid=True,\n",
    "                   x=gdppc_col, y=lifesat_col)\n",
    "\n",
    "# Definimos los valores mÃ­nimo y mÃ¡ximo de satisfacciÃ³n con la vida\n",
    "# para ajustar los lÃ­mites del eje Y en el grÃ¡fico.\n",
    "# Puedes probar tambiÃ©n a cambiarlos para jugar con Matplotlib\n",
    "min_life_sat = 4\n",
    "max_life_sat = 9\n",
    "\n",
    "# Creamos un diccionario con algunos paÃ­ses seleccionados y las coordenadas\n",
    "# donde se colocarÃ¡ la etiqueta (texto) de cada uno dentro del grÃ¡fico\n",
    "position_text = {\n",
    "    \"Turkey\": (29_500, 4.2),\n",
    "    \"Hungary\": (28_000, 6.9),\n",
    "    \"France\": (40_000, 5),\n",
    "    \"New Zealand\": (28_000, 8.2),\n",
    "    \"Australia\": (50_000, 5.5),\n",
    "    \"United States\": (59_000, 5.3),\n",
    "    \"Denmark\": (46_000, 8.5)\n",
    "}\n",
    "\n",
    "# Recorremos cada paÃ­s del diccionario para aÃ±adir su nombre al grÃ¡fico\n",
    "for country, pos_text in position_text.items():\n",
    "    # Obtenemos las coordenadas reales del paÃ­s (sus valores en los datos)\n",
    "    pos_data_x = country_stats[gdppc_col].loc[country]\n",
    "    pos_data_y = country_stats[lifesat_col].loc[country]\n",
    "\n",
    "    # Ajuste estÃ©tico: cambiamos el nombre \"United States\" por \"U.S.\" en la etiqueta\n",
    "    # GerÃ³n dejÃ³ aquÃ­ esta lÃ­nea, pero no es muy eficiente. Te reto a que\n",
    "    # me digas por quÃ©.\n",
    "    country = \"U.S.\" if country == \"United States\" else country\n",
    "\n",
    "    # AÃ±adimos una etiqueta con el nombre del paÃ­s y una flecha que apunta al punto correspondiente\n",
    "    plt.annotate(\n",
    "        country,                      # El texto que queremos mostrar (nombre del paÃ­s)\n",
    "        xy=(pos_data_x, pos_data_y),  # Coordenadas del punto real en el grÃ¡fico (donde se encuentra el paÃ­s)\n",
    "        xytext=pos_text,              # Coordenadas donde se colocarÃ¡ la etiqueta (para no tapar el punto)\n",
    "        fontsize=12,                  # TamaÃ±o del texto de la etiqueta\n",
    "        arrowprops=dict(               # Propiedades de la flecha que conecta la etiqueta con el punto\n",
    "            facecolor='black',        # Color de la flecha\n",
    "            width=0.5,                # Grosor de la lÃ­nea de la flecha\n",
    "            shrink=0.08,              # Acorta la flecha para que no toque directamente el marcador\n",
    "            headwidth=5               # Ancho de la cabeza de la flecha\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Marcamos el punto del paÃ­s con un pequeÃ±o cÃ­rculo rojo\n",
    "    plt.plot(pos_data_x, pos_data_y, \"ro\")\n",
    "\n",
    "# Ajustamos los lÃ­mites de los ejes X e Y para encuadrar bien el grÃ¡fico\n",
    "plt.axis([min_gdp, max_gdp, min_life_sat, max_life_sat])\n",
    "\n",
    "# Guardamos la figura con un nombre de archivo\n",
    "save_fig('money_happy_scatterplot')\n",
    "\n",
    "# Mostramos el grÃ¡fico final en pantalla\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En su libro, GerÃ³n indica que parece que hay una tendencia aquÃ­. Aunque los datos son ruidosos (es decir, parcialmente aleatorios), parece que la satisfacciÃ³n con la vida aumenta mÃ¡s o menos de manera lineal a medida que crece el PIB per cÃ¡pita de un paÃ­s. Por lo tanto, se imagina que querriamos modelar la satisfacciÃ³n con la vida como una funciÃ³n lineal del PIB per cÃ¡pita. Este paso se llama, comenta en su libro, selecciÃ³n de modelo: hemos seleccionado un modelo lineal de satisfacciÃ³n con la vida con un solo atributo, el PIB per cÃ¡pita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente cÃ³digo selecciona un subconjunto de paÃ­ses especÃ­ficos (los que se habÃ­an destacado con etiquetas en el grÃ¡fico) y muestra sus valores de PIB per cÃ¡pita y satisfacciÃ³n con la vida, ordenados por PIB.\n",
    "Es Ãºtil para ver de manera clara los datos de los paÃ­ses destacados y compararlos entre sÃ­."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos Ãºnicamente los paÃ­ses que queremos resaltar en el grÃ¡fico\n",
    "# `position_text.keys()` contiene los nombres de los paÃ­ses que hemos etiquetado\n",
    "# `loc` permite acceder a las filas de un DataFrame usando los nombres del Ã­ndice (paÃ­ses)\n",
    "highlighted_countries = country_stats.loc[list(position_text.keys())]\n",
    "\n",
    "# Mostramos solo las columnas de interÃ©s: PIB per cÃ¡pita y SatisfacciÃ³n con la vida\n",
    "# AdemÃ¡s, ordenamos los paÃ­ses por el PIB per cÃ¡pita para comparar mÃ¡s fÃ¡cilmente\n",
    "# Si en sort_values() no indicamos nada mÃ¡s, , ascending=True por defecto, es decir,\n",
    "# La columna por la que se ordena lo harÃ¡ de menor a mayor.\n",
    "highlighted_countries[[gdppc_col, lifesat_col]].sort_values(by=gdppc_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente cÃ³digo crea un grÃ¡fico que muestra cÃ³mo se relacionan dos variables:\n",
    "\n",
    "1. El PIB per cÃ¡pita de un paÃ­s (es decir, cuÃ¡nto dinero produce por persona)\n",
    "2. Su nivel de satisfacciÃ³n con la vida.\n",
    "\n",
    "Primero, GerÃ³n dibuja los puntos correspondientes a cada paÃ­s.\n",
    "Luego, aÃ±ade tres lÃ­neas rectas que representan tres modelos diferentes.\n",
    "Cada una tiene valores distintos del tÃ©rmino independiente (w1) y pendiente (w2), que determinan dÃ³nde empieza la lÃ­nea y cuÃ¡nto se inclina.\n",
    "\n",
    "Al mostrar las tres lÃ­neas a la vez, el cÃ³digo permite comparar cÃ³mo cambia la predicciÃ³n cuando modificamos estos parÃ¡metros. AsÃ­ podemos ver quÃ© combinaciones se acercan mejor a los datos reales.\n",
    "\n",
    "Finalmente, guarda el grÃ¡fico como imagen y lo muestra en pantalla.\n",
    "\n",
    "Con este ejemplo, GerÃ³n quiere mostrar de forma visual e intuitiva cÃ³mo funcionan los parÃ¡metros de un modelo lineal.\n",
    "\n",
    "* El parÃ¡metro Î¸â‚€ (tÃ©rmino independiente) mueve la lÃ­nea hacia arriba o hacia abajo.\n",
    "* El parÃ¡metro Î¸â‚ (pendiente) controla la inclinaciÃ³n: si la lÃ­nea sube o baja con el PIB.\n",
    "\n",
    "Al variar estos valores, podemos ver cÃ³mo la lÃ­nea se ajusta mejor o peor a los puntos de los paÃ­ses.\n",
    "\n",
    "Este ejercicio sirve como introducciÃ³n a la regresiÃ³n lineal, una tÃ©cnica que busca la mejor lÃ­nea posible para representar la relaciÃ³n entre dos variables.\n",
    "\n",
    "En resumen, GerÃ³n utiliza este grÃ¡fico para que entendamos cÃ³mo los parÃ¡metros dan forma al modelo y por quÃ© elegir los valores adecuados es clave para hacer buenas predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Creamos un grÃ¡fico de dispersiÃ³n (scatter plot) con los datos de los paÃ­ses\n",
    "# Eje X: PIB per cÃ¡pita, Eje Y: SatisfacciÃ³n con la vida\n",
    "# figsize define el tamaÃ±o del grÃ¡fico y grid=True aÃ±ade la cuadrÃ­cula\n",
    "country_stats.plot(kind='scatter', figsize=(6, 3), grid=True,\n",
    "                   x=gdppc_col, y=lifesat_col)\n",
    "\n",
    "# Creamos un array de valores de PIB per cÃ¡pita uniformemente distribuidos\n",
    "# Esto se usarÃ¡ para dibujar las lÃ­neas de los modelos lineales\n",
    "X = np.linspace(min_gdp, max_gdp, 1000)\n",
    "\n",
    "# -------- Primer modelo --------\n",
    "w1, w2 = 4.2, 0  # Definimos los parÃ¡metros del modelo lineal (tÃ©rmino independiente y pendiente)\n",
    "plt.plot(X, w1 + w2 * 1e-5 * X, \"r\")  # Dibujamos la lÃ­nea roja correspondiente al modelo\n",
    "# AÃ±adimos etiquetas de los parÃ¡metros del modelo en el grÃ¡fico\n",
    "plt.text(40_000, 4.9, fr\"$\\theta_0 = {w1}$\", color=\"r\")  # TÃ©rmino independiente\n",
    "plt.text(40_000, 4.4, fr\"$\\theta_1 = {w2}$\", color=\"r\")   # Pendiente\n",
    "\n",
    "# -------- Segundo modelo --------\n",
    "w1, w2 = 10, -9\n",
    "plt.plot(X, w1 + w2 * 1e-5 * X, \"g\")  # LÃ­nea verde\n",
    "plt.text(26_000, 8.5, fr\"$\\theta_0 = {w1}$\", color=\"g\")\n",
    "plt.text(26_000, 8.0, fr\"$\\theta_1 = {w2} \\times 10^{{-5}}$\", color=\"g\")\n",
    "\n",
    "# -------- Tercer modelo --------\n",
    "w1, w2 = 3, 8\n",
    "plt.plot(X, w1 + w2 * 1e-5 * X, \"b\")  # LÃ­nea azul\n",
    "plt.text(48_000, 8.5, fr\"$\\theta_0 = {w1}$\", color=\"b\")\n",
    "plt.text(48_000, 8.0, fr\"$\\theta_1 = {w2} \\times 10^{{-5}}$\", color=\"b\")\n",
    "\n",
    "# Ajustamos los lÃ­mites de los ejes para que se vea todo el rango de datos\n",
    "plt.axis([min_gdp, max_gdp, min_life_sat, max_life_sat])\n",
    "\n",
    "# Guardamos la figura con el nombre 'tweaking_model_params_plot'\n",
    "save_fig('tweaking_model_params_plot')\n",
    "\n",
    "# Mostramos el grÃ¡fico final en pantalla\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AquÃ­ es donde entra en juego el **algoritmo de regresiÃ³n lineal**: se le proporcionan los ejemplos de entrenamiento (en este caso, los datos de los paÃ­ses con su PIB per cÃ¡pita y su nivel de satisfacciÃ³n con la vida), y el algoritmo **encuentra los parÃ¡metros** que hacen que el modelo lineal se ajuste **lo mejor posible a los datos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el mÃ³dulo de regresiÃ³n lineal de scikit-learn\n",
    "# Este mÃ³dulo nos permite crear modelos de regresiÃ³n lineal fÃ¡cilmente\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Creamos las variables de entrada (X) y salida (y) para el modelo\n",
    "# X_sample: matriz con los valores de PIB per cÃ¡pita de los paÃ­ses\n",
    "# y_sample: matriz con los valores de satisfacciÃ³n con la vida de los paÃ­ses\n",
    "# [[ ]] se usa para asegurarnos de que sean matrices 2D, como requiere sklearn\n",
    "X_sample = country_stats[[gdppc_col]].values\n",
    "y_sample = country_stats[[lifesat_col]].values\n",
    "\n",
    "# Creamos un objeto de regresiÃ³n lineal\n",
    "# Este objeto representa un modelo lineal que aprenderÃ¡ la relaciÃ³n entre X e y\n",
    "lin1 = linear_model.LinearRegression()\n",
    "\n",
    "# Entrenamos (ajustamos) el modelo usando los datos de entrada y salida\n",
    "# El mÃ©todo fit encuentra los parÃ¡metros Ã³ptimos Î¸0 (intercepto) y Î¸1 (pendiente)\n",
    "lin1.fit(X_sample, y_sample)\n",
    "\n",
    "# Extraemos los parÃ¡metros aprendidos por el modelo\n",
    "# lin1.intercept_ â†’ el intercepto Î¸0\n",
    "# lin1.coef_ â†’ la pendiente Î¸1 (coef_ es un array, usamos ravel() para convertirlo a 1D)\n",
    "t0, t1 = lin1.intercept_[0], lin1.coef_.ravel()[0]\n",
    "\n",
    "# Mostramos los valores aprendidos de los parÃ¡metros en la consola\n",
    "# {:.2f} â†’ formato con 2 decimales para el intercepto\n",
    "# {:.2e} â†’ formato en notaciÃ³n cientÃ­fica para la pendiente\n",
    "print(f\"Î¸0={t0:.2f}, Î¸1={t1:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A este proceso se le llama **entrenar el modelo**.\n",
    "En este ejemplo, el algoritmo determina que los valores Ã³ptimos de los parÃ¡metros son:\n",
    "\n",
    "[Î¸0=3.75, Î¸1=6.78e-05]\n",
    "\n",
    "âš ï¸ **Advertencia sobre el tÃ©rmino \"modelo\"**\n",
    "El tÃ©rmino *modelo* puede referirse a distintas cosas:\n",
    "\n",
    "* A un **tipo de modelo**, como la regresiÃ³n lineal.\n",
    "* A una **arquitectura especÃ­fica**, por ejemplo, una regresiÃ³n lineal con una variable de entrada (PIB per cÃ¡pita) y una de salida (satisfacciÃ³n con la vida).\n",
    "* O al **modelo ya entrenado**, listo para hacer predicciones, que en este caso serÃ­a una regresiÃ³n lineal con los parÃ¡metros aprendidos:\n",
    "  [Î¸0=3.75, Î¸1=6.78e-05]\n",
    "\n",
    "La **selecciÃ³n del modelo** consiste en escoger quÃ© tipo de modelo se va a usar y definir su estructura.\n",
    "El **entrenamiento del modelo** consiste en ejecutar un algoritmo que encuentre los valores de los parÃ¡metros que mejor se ajusten a los datos de entrenamiento, de forma que el modelo pueda luego hacer **buenas predicciones con nuevos datos**.\n",
    "\n",
    "Una vez entrenado, el modelo se ajusta a los datos de entrenamiento **todo lo posible** (para un modelo lineal).\n",
    "\n",
    "Ahora el modelo estÃ¡ listo para hacer **predicciones**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un grÃ¡fico de dispersiÃ³n de los paÃ­ses\n",
    "# kind='scatter' â†’ grÃ¡fico de puntos\n",
    "# figsize=(5,3) â†’ tamaÃ±o del grÃ¡fico\n",
    "# grid=True â†’ aÃ±ade cuadrÃ­cula\n",
    "# x=gdppc_col â†’ eje X: PIB per cÃ¡pita\n",
    "# y=lifesat_col â†’ eje Y: SatisfacciÃ³n con la vida\n",
    "country_stats.plot(kind='scatter', figsize=(6, 3), grid=True,\n",
    "                   x=gdppc_col, y=lifesat_col)\n",
    "\n",
    "# Generamos un array de 1000 puntos uniformemente distribuidos entre min_gdp y max_gdp\n",
    "# Esto servirÃ¡ para dibujar la lÃ­nea de regresiÃ³n\n",
    "X = np.linspace(min_gdp, max_gdp, 1000)\n",
    "\n",
    "# Dibujamos la lÃ­nea de regresiÃ³n lineal ajustada con los parÃ¡metros aprendidos t0 y t1\n",
    "# \"b\" â†’ color azul\n",
    "plt.plot(X, t0 + t1 * X, \"b\")\n",
    "\n",
    "# AÃ±adimos el texto del intercepto Î¸0 en el grÃ¡fico\n",
    "# Se coloca cerca del borde inferior derecho para no tapar los puntos\n",
    "plt.text(max_gdp - 20_000, min_life_sat + 1.9,\n",
    "         fr\"$\\theta_0 = {t0:.2f}$\", color=\"b\")\n",
    "\n",
    "# AÃ±adimos el texto de la pendiente Î¸1 en el grÃ¡fico\n",
    "# Multiplicamos t1 por 1e5 para mostrarlo de manera mÃ¡s legible en notaciÃ³n cientÃ­fica\n",
    "plt.text(max_gdp - 20_000, min_life_sat + 1.3,\n",
    "         fr\"$\\theta_1 = {t1 * 1e5:.2f} \\times 10^{{-5}}$\", color=\"b\")\n",
    "\n",
    "# Ajustamos los lÃ­mites de los ejes X y Y para que se vea todo el rango de datos y la lÃ­nea\n",
    "plt.axis([min_gdp, max_gdp, min_life_sat, max_life_sat])\n",
    "\n",
    "# Guardamos la figura con el nombre 'best_fit_model_plot'\n",
    "save_fig('best_fit_model_plot')\n",
    "\n",
    "# Mostramos el grÃ¡fico final en pantalla\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya estamos listo para usar el modelo para hacer predicciones. Por ejemplo, supongamos que queremos saber cuÃ¡l es el nivel de felicidad de los chipriotas (GerÃ³n usa este ejemplo en su libro), pero los datos de la OCDE no incluyen esa informaciÃ³n. Por suerte, podemos utilizar el modelo para hacer una buena estimaciÃ³n: buscamos el PIB per cÃ¡pita de Chipre, que es de 37.655 dÃ³lares, y luego aplicamos el modelo para predecir el nivel de satisfacciÃ³n con la vida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyprus_gdp_per_capita = gdp_per_capita[gdppc_col].loc[\"Cyprus\"]\n",
    "cyprus_gdp_per_capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos el modelo entrenado (lin1) para hacer una predicciÃ³n\n",
    "# lin1.predict() espera una matriz (2D), por eso se ponen los dobles corchetes [[...]]\n",
    "# En este caso, le damos el PIB per cÃ¡pita de Chipre como entrada\n",
    "cyprus_predicted_life_satisfaction = lin1.predict([[cyprus_gdp_per_capita]])[0, 0]\n",
    "\n",
    "# Mostramos en pantalla el valor predicho de satisfacciÃ³n con la vida para Chipre\n",
    "cyprus_predicted_life_satisfaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AquÃ­ hemos usado el modelo de regresiÃ³n lineal entrenado (lin1) para hacer una predicciÃ³n.\n",
    "\n",
    "Le pasamos como entrada al modelo el PIB per cÃ¡pita de Chipre (cyprus_gdp_per_capita).\n",
    "\n",
    "El mÃ©todo .predict() devuelve una matriz 2D con el resultado (porque asÃ­ trabaja scikit-learn). Por eso se accede al primer elemento con [0, 0] para obtener solo el nÃºmero.\n",
    "\n",
    "Si estÃ¡s interesado en mÃ¡s informaciÃ³n sobre el modelo de regresiÃ³n lineal de scikit-learn, aquÃ­ te dejo el enlace a la documentaciÃ³n oficial: https://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a mostrar visualmente la predicciÃ³n del modelo lineal para Chipre dentro del contexto de todos los paÃ­ses. Para esto, GerÃ³n dibuja los datos reales (puntos de paÃ­ses) en un grÃ¡fico de dispersiÃ³n y traza la lÃ­nea azul del modelo lineal ajustado (la relaciÃ³n aprendida entre PIB per cÃ¡pita y satisfacciÃ³n).\n",
    "\n",
    "Para remarcar la predicciÃ³n hecha para Chipre, marca su posiciÃ³n, y dibuja una lÃ­nea roja discontinua que sube desde su PIB hasta la predicciÃ³n del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un grÃ¡fico de dispersiÃ³n con los datos reales\n",
    "# Cada punto representa un paÃ­s, mostrando la relaciÃ³n entre\n",
    "# PIB per cÃ¡pita (eje X) y satisfacciÃ³n con la vida (eje Y)\n",
    "country_stats.plot(kind='scatter', figsize=(6, 3), grid=True,\n",
    "                   x=gdppc_col, y=lifesat_col)\n",
    "\n",
    "# Generamos un rango de valores de PIB entre el mÃ­nimo y el mÃ¡ximo\n",
    "# Esto servirÃ¡ para dibujar la lÃ­nea de regresiÃ³n\n",
    "X = np.linspace(min_gdp, max_gdp, 1000)\n",
    "\n",
    "# Dibujamos la lÃ­nea azul del modelo lineal entrenado (la \"mejor lÃ­nea de ajuste\")\n",
    "# t0 = intercepto, t1 = pendiente\n",
    "# Estos valores ya se calcularon cuando se entrenÃ³ el modelo\n",
    "plt.plot(X, t0 + t1 * X, \"b\")\n",
    "\n",
    "# Mostramos en el grÃ¡fico los valores de los parÃ¡metros del modelo (Î¸0 y Î¸1)\n",
    "# Se colocan cerca de la parte superior derecha para que sean visibles\n",
    "plt.text(min_gdp + 22_000, max_life_sat - 1.1,\n",
    "         fr\"$\\theta_0 = {t0:.2f}$\", color=\"b\")\n",
    "plt.text(min_gdp + 22_000, max_life_sat - 0.6,\n",
    "         fr\"$\\theta_1 = {t1 * 1e5:.2f} \\times 10^{{-5}}$\", color=\"b\")\n",
    "\n",
    "# Dibujamos una lÃ­nea discontinua roja (r--) que marca visualmente la predicciÃ³n de Chipre\n",
    "# Va desde el eje X (PIB de Chipre) hasta la predicciÃ³n en el eje Y\n",
    "plt.plot([cyprus_gdp_per_capita, cyprus_gdp_per_capita],\n",
    "         [min_life_sat, cyprus_predicted_life_satisfaction], \"r--\")\n",
    "\n",
    "# AÃ±adimos una etiqueta de texto junto a la lÃ­nea roja\n",
    "# Muestra el valor predicho de satisfacciÃ³n con la vida para Chipre\n",
    "plt.text(cyprus_gdp_per_capita + 1000, 5.0,\n",
    "         fr\"Prediction = {cyprus_predicted_life_satisfaction:.2f}\", color=\"r\")\n",
    "\n",
    "# Dibujamos un punto rojo en la posiciÃ³n exacta de la predicciÃ³n\n",
    "plt.plot(cyprus_gdp_per_capita, cyprus_predicted_life_satisfaction, \"ro\")\n",
    "\n",
    "# Ajustamos los lÃ­mites de los ejes X e Y\n",
    "# Esto asegura que se vea todo el rango de datos, la lÃ­nea de regresiÃ³n y la predicciÃ³n\n",
    "plt.axis([min_gdp, max_gdp, min_life_sat, max_life_sat])\n",
    "\n",
    "# Mostramos el grÃ¡fico completo en pantalla\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder generalizar bien, es fundamental que los datos de entrenamiento sean representativos de los nuevos casos sobre los que queremos generalizar. Esto es cierto tanto si usamos aprendizaje basado en instancias como si usamos aprendizaje basado en modelos.\n",
    "\n",
    "Por ejemplo, el conjunto de paÃ­ses que se utilizamos antes para entrenar el modelo lineal no era perfectamente representativo: no incluÃ­a ningÃºn paÃ­s con un PIB per cÃ¡pita inferior a 23.500$ ni superior a 62.500$.\n",
    "\n",
    "Vamos a generar ahora una figura, como hace GerÃ³n en su libro, que muestra cÃ³mo se ven los datos cuando se aÃ±aden paÃ­ses en esos rangos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos los paÃ­ses que estÃ¡n fuera del rango de PIB per cÃ¡pita usado antes (min_gdp y max_gdp)\n",
    "# Es decir, seleccionamos los paÃ­ses \"faltantes\" (muy pobres o muy ricos)\n",
    "missing_data = full_country_stats[(full_country_stats[gdppc_col] < min_gdp) |\n",
    "                                  (full_country_stats[gdppc_col] > max_gdp)]\n",
    "missing_data  # Mostramos los datos de estos paÃ­ses faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario con los paÃ­ses faltantes y las coordenadas donde se colocarÃ¡n sus etiquetas en el grÃ¡fico\n",
    "position_text_missing_countries = {\n",
    "    \"South Africa\": (20_000, 4.2),\n",
    "    \"Colombia\": (6_000, 8.2),\n",
    "    \"Brazil\": (18_000, 7.8),\n",
    "    \"Mexico\": (24_000, 7.4),\n",
    "    \"Chile\": (30_000, 7.0),\n",
    "    \"Norway\": (51_000, 6.2),\n",
    "    \"Switzerland\": (62_000, 5.7),\n",
    "    \"Ireland\": (81_000, 5.2),\n",
    "    \"Luxembourg\": (92_000, 4.7),\n",
    "}\n",
    "\n",
    "# Dibujamos un grÃ¡fico de dispersiÃ³n (PIB per cÃ¡pita vs. satisfacciÃ³n con la vida)\n",
    "full_country_stats.plot(kind='scatter', figsize=(8, 3),\n",
    "                        x=gdppc_col, y=lifesat_col, grid=True)\n",
    "\n",
    "# Recorremos los paÃ­ses faltantes y los aÃ±adimos al grÃ¡fico con una etiqueta y una flecha\n",
    "for country, pos_text in position_text_missing_countries.items():\n",
    "    # Obtenemos los valores reales de PIB y satisfacciÃ³n para ese paÃ­s\n",
    "    pos_data_x, pos_data_y = missing_data.loc[country]\n",
    "\n",
    "    # Dibujamos el nombre del paÃ­s con una flecha que apunta a su punto\n",
    "    plt.annotate(country, xy=(pos_data_x, pos_data_y),\n",
    "                 xytext=pos_text, fontsize=12,\n",
    "                 arrowprops=dict(facecolor='black', width=0.5,\n",
    "                                 shrink=0.08, headwidth=5))\n",
    "    # Marcamos el punto del paÃ­s en rojo (sÃ­mbolo 'rs' = red square)\n",
    "    plt.plot(pos_data_x, pos_data_y, \"rs\")\n",
    "\n",
    "# Creamos un rango de valores de PIB para dibujar las lÃ­neas del modelo\n",
    "X = np.linspace(0, 115_000, 1000)\n",
    "\n",
    "# Dibujamos la lÃ­nea discontinua azul: es el modelo lineal original (entrenado con menos datos)\n",
    "plt.plot(X, t0 + t1 * X, \"b:\")\n",
    "\n",
    "# Entrenamos un nuevo modelo lineal pero ahora con *todos* los paÃ­ses (mÃ¡s representativo)\n",
    "lin_reg_full = linear_model.LinearRegression()\n",
    "\n",
    "# Preparamos los datos completos (todas las filas y columnas necesarias)\n",
    "Xfull = np.c_[full_country_stats[gdppc_col]]      # PIB per cÃ¡pita\n",
    "yfull = np.c_[full_country_stats[lifesat_col]]    # SatisfacciÃ³n con la vida\n",
    "\n",
    "# Ajustamos el modelo a todos los datos\n",
    "lin_reg_full.fit(Xfull, yfull)\n",
    "\n",
    "# Obtenemos los nuevos parÃ¡metros del modelo (intercepto y pendiente)\n",
    "t0full, t1full = lin_reg_full.intercept_[0], lin_reg_full.coef_.ravel()[0]\n",
    "\n",
    "# Dibujamos la nueva lÃ­nea de regresiÃ³n (en negro)\n",
    "plt.plot(X, t0full + t1full * X, \"k\")\n",
    "\n",
    "# Ajustamos los lÃ­mites del grÃ¡fico\n",
    "plt.axis([0, 115_000, min_life_sat, max_life_sat])\n",
    "\n",
    "# Guardamos la figura y la mostramos\n",
    "save_fig('representative_training_data_scatterplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si entrenamos un modelo lineal con este nuevo conjunto de datos, obtenemos la lÃ­nea continua, mientras que el modelo anterior se representa con la lÃ­nea discontinua.\n",
    "\n",
    "Como puede verse, aÃ±adir solo unos pocos paÃ­ses faltantes altera significativamente el modelo y deja claro que un modelo lineal tan simple probablemente no funcionarÃ¡ bien. Parece que los paÃ­ses muy ricos no son mÃ¡s felices que los moderadamente ricos (de hecho, parecen un poco menos felices), y, por el contrario, algunos paÃ­ses pobres parecen mÃ¡s felices que muchos ricos.\n",
    "\n",
    "Al usar un conjunto de entrenamiento no representativo, se entrenÃ³ un modelo que probablemente no harÃ¡ predicciones precisas, especialmente para los paÃ­ses muy pobres o muy ricos.\n",
    "\n",
    "Es fundamental usar un conjunto de entrenamiento representativo de los casos que se quieren generalizar. Sin embargo, esto suele ser mÃ¡s difÃ­cil de lo que parece: si la muestra es demasiado pequeÃ±a, aparecerÃ¡ ruido de muestreo (es decir, datos no representativos por azar), pero incluso muestras muy grandes pueden ser no representativas si el mÃ©todo de muestreo es incorrecto.\n",
    "A esto se le llama sesgo de muestreo (sampling bias)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TambiÃ©n puede ocurrir lo contrario: cuando un modelo se ajusta demasiado a los datos de entrenamiento, pero no funciona bien con nuevos datos, decimos que hay sobreajuste (overfitting).\n",
    "\n",
    "GerÃ³n explica que un modelo muy complejo â€”como uno polinÃ³mico de alto grado o una red neuronal profundaâ€” puede detectar patrones muy sutiles, incluso aquellos que son simplemente ruido o coincidencias en los datos. Por ejemplo, un modelo podrÃ­a detectar que los paÃ­ses con una \"w\" en su nombre tienen una satisfacciÃ³n alta, algo claramente casual.\n",
    "\n",
    "En esos casos, el modelo parece funcionar muy bien con los datos de entrenamiento, pero falla al generalizar a nuevas situaciones.\n",
    "\n",
    "Por resumir: el overfitting ocurre cuando un modelo aprende demasiado bien los detalles del conjunto de entrenamiento â€”incluyendo el ruido o coincidencias irrelevantesâ€”, lo que hace que pierda capacidad para predecir correctamente en nuevos casos. Veamos el ejemplo que propone GerÃ³n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "\n",
    "# Dibuja los datos originales: cada punto representa un paÃ­s\n",
    "# Eje X: PIB per cÃ¡pita (GDP per capita)\n",
    "# Eje Y: SatisfacciÃ³n con la vida (Life Satisfaction)\n",
    "full_country_stats.plot(kind='scatter', figsize=(8, 3),\n",
    "                        x=gdppc_col, y=lifesat_col, grid=True)\n",
    "\n",
    "# Crea una transformaciÃ³n polinÃ³mica de grado 10.\n",
    "# Esto genera nuevas caracterÃ­sticas (x, xÂ², xÂ³, ..., xÂ¹â°) a partir del PIB per cÃ¡pita.\n",
    "# Permite que el modelo capture relaciones no lineales entre PIB y satisfacciÃ³n.\n",
    "poly = preprocessing.PolynomialFeatures(degree=10, include_bias=False)\n",
    "\n",
    "# Escala los datos para que todas las caracterÃ­sticas (x, xÂ², xÂ³...) estÃ©n en la misma escala.\n",
    "# Esto mejora la estabilidad numÃ©rica y el rendimiento del modelo.\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Crea un modelo de regresiÃ³n lineal.\n",
    "# Aunque el modelo es lineal respecto a las caracterÃ­sticas polinÃ³micas, el resultado serÃ¡ una curva no lineal.\n",
    "lin_reg2 = linear_model.LinearRegression()\n",
    "\n",
    "# Crea una \"pipeline\" que encadena las tres etapas:\n",
    "# 1. Generar caracterÃ­sticas polinÃ³micas.\n",
    "# 2. Escalar los datos.\n",
    "# 3. Ajustar la regresiÃ³n lineal.\n",
    "pipeline_reg = pipeline.Pipeline([\n",
    "    ('poly', poly),\n",
    "    ('scal', scaler),\n",
    "    ('lin', lin_reg2)\n",
    "])\n",
    "\n",
    "# Entrena el modelo usando todos los datos disponibles.\n",
    "pipeline_reg.fit(Xfull, yfull)\n",
    "\n",
    "# Predice los valores de satisfacciÃ³n para muchos valores de PIB (X).\n",
    "# np.newaxis convierte X en una matriz columna (forma correcta para sklearn).\n",
    "curve = pipeline_reg.predict(X[:, np.newaxis])\n",
    "\n",
    "# Dibuja la curva ajustada por el modelo sobre el grÃ¡fico de dispersiÃ³n.\n",
    "plt.plot(X, curve)\n",
    "\n",
    "# Define los lÃ­mites de los ejes.\n",
    "plt.axis([0, 115_000, min_life_sat, max_life_sat])\n",
    "\n",
    "# Guarda la figura con un nombre descriptivo.\n",
    "save_fig('overfitting_model_plot')\n",
    "\n",
    "# Muestra el grÃ¡fico final.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El cÃ³digo anterior crea y entrena un modelo polinÃ³mico de grado 10 para predecir la satisfacciÃ³n con la vida a partir del PIB per cÃ¡pita, usando una pipeline que automatiza las etapas de:\n",
    "\n",
    "1. Generar caracterÃ­sticas polinÃ³micas.\n",
    "2. Escalar los datos.\n",
    "3. Ajustar una regresiÃ³n lineal.\n",
    "\n",
    "Finalmente, el cÃ³digo dibuja la curva resultante sobre el grÃ¡fico de dispersiÃ³n de los paÃ­ses para mostrar cÃ³mo el modelo se ajusta (o sobreajusta) a los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el modelo lineal que definimos antes tiene dos parÃ¡metros, Î¸â‚€ y Î¸â‚. Esto da al algoritmo de aprendizaje **dos grados de libertad** para adaptarse a los datos de entrenamiento: puede ajustar tanto la **altura** (Î¸â‚€, el intercepto) como la **pendiente** (Î¸â‚).\n",
    "\n",
    "Si obligamos a que Î¸â‚ = 0, el algoritmo solo podrÃ­a mover la lÃ­nea hacia arriba o hacia abajo, pero no cambiar su inclinaciÃ³n, asÃ­ que la lÃ­nea se ajustarÃ­a mÃ¡s o menos al promedio: serÃ­a un modelo muy simple.\n",
    "\n",
    "Por otro lado, si permitimos modificar Î¸â‚ pero le forzamos a mantenerlo **pequeÃ±o**, el algoritmo tendrÃ¡ una flexibilidad intermedia: ni tan rÃ­gido como el caso anterior, ni tan libre como sin restricciÃ³n.\n",
    "\n",
    "Restringir un modelo para hacerlo mÃ¡s simple y reducir el riesgo de sobreajuste se llama **regularizaciÃ³n**.\n",
    "\n",
    "El objetivo es **encontrar el equilibrio adecuado** entre:\n",
    "\n",
    "* Ajustar bien los datos de entrenamiento, y\n",
    "* Mantener el modelo lo suficientemente simple como para generalizar bien a nuevos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Piensa en la **regularizaciÃ³n** como una forma de \"ponerle lÃ­mites\" al modelo para que no se complique demasiado.\n",
    "\n",
    "ðŸ‘‰ Si un modelo tiene demasiada libertad, puede **memorizar** los datos de entrenamiento, incluso los errores o el ruido (eso es **overfitting**).\n",
    "\n",
    "ðŸ‘‰ Si lo restringes demasiado, no aprenderÃ¡ lo suficiente (eso serÃ­a **underfitting**).\n",
    "\n",
    "La regularizaciÃ³n es como decirle:\n",
    "\n",
    "> \"Ajusta la lÃ­nea a los datos, pero no te obsesiones con seguir cada punto al milÃ­metro.\"\n",
    "\n",
    "Este equilibrio entre **precisiÃ³n y simplicidad** es lo que permite construir modelos que realmente funcionan en el mundo real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibuja los paÃ­ses usados para entrenar el modelo inicial (datos parciales)\n",
    "country_stats.plot(kind='scatter', x=gdppc_col, y=lifesat_col, figsize=(8, 3))\n",
    "\n",
    "# Dibuja los paÃ­ses \"faltantes\" (datos que no se usaron en el primer modelo) en rojo con forma de cuadrado\n",
    "# Usa el mismo eje del grÃ¡fico anterior (ax=plt.gca()) para superponerlos\n",
    "missing_data.plot(kind='scatter', x=gdppc_col, y=lifesat_col,\n",
    "                  marker=\"s\", color=\"r\", grid=True, ax=plt.gca())\n",
    "\n",
    "# Crea una secuencia de valores de PIB per cÃ¡pita (de 0 a 115,000) para dibujar las lÃ­neas de regresiÃ³n\n",
    "X = np.linspace(0, 115_000, 1000)\n",
    "\n",
    "# Dibuja la lÃ­nea azul punteada (:) del modelo entrenado con los datos parciales\n",
    "plt.plot(X, t0 + t1*X, \"b:\", label=\"Modelo lineal en datos parciales\")\n",
    "\n",
    "# Dibuja la lÃ­nea negra sÃ³lida del modelo entrenado con todos los paÃ­ses (datos completos)\n",
    "plt.plot(X, t0full + t1full * X, \"k-\", label=\"Modelo lineal sobre todos los datos\")\n",
    "\n",
    "# Crea un modelo lineal regularizado (Ridge Regression)\n",
    "# alpha controla el grado de regularizaciÃ³n (muy alto = mÃ¡s restricciÃ³n = lÃ­nea mÃ¡s plana)\n",
    "ridge = linear_model.Ridge(alpha=10**9.5)\n",
    "\n",
    "# Extrae las columnas de entrada (PIB) y salida (satisfacciÃ³n)\n",
    "X_sample = country_stats[[gdppc_col]]\n",
    "y_sample = country_stats[[lifesat_col]]\n",
    "\n",
    "# Entrena el modelo Ridge usando solo los datos parciales\n",
    "ridge.fit(X_sample, y_sample)\n",
    "\n",
    "# Obtiene los parÃ¡metros del modelo entrenado: intercepto (t0ridge) y pendiente (t1ridge)\n",
    "t0ridge, t1ridge = ridge.intercept_[0], ridge.coef_.ravel()[0]\n",
    "\n",
    "# Dibuja la lÃ­nea azul discontinua (--), correspondiente al modelo regularizado\n",
    "plt.plot(X, t0ridge + t1ridge * X, \"b--\",\n",
    "         label=\"Modelo lineal regularizado sobre datos parciales\")\n",
    "\n",
    "# AÃ±ade una leyenda en la parte inferior derecha\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Define los lÃ­mites de los ejes (PIB per cÃ¡pita y satisfacciÃ³n)\n",
    "plt.axis([0, 115_000, min_life_sat, max_life_sat])\n",
    "\n",
    "# Guarda la figura como archivo\n",
    "save_fig('ridge_model_plot')\n",
    "\n",
    "# Muestra el grÃ¡fico final\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 02. Proyecto de Machine Learning de Extremo a Extremo\n",
    "\n",
    "En este capÃ­tulo se desarrolla un ejemplo completo de un proyecto de *machine learning*, asumiendo el papel de un cientÃ­fico de datos reciÃ©n contratado en una empresa inmobiliaria. El ejemplo es ficticio: el objetivo no es aprender sobre bienes raÃ­ces, sino entender **todas las etapas de un proyecto de ML real**.\n",
    "\n",
    "Pasos en el proyecto:\n",
    "\n",
    "1.  **Ver la visiÃ³n general** â€” Comprender el problema y el objetivo del proyecto.\n",
    "2. **Obtener los datos** â€” Reunir las fuentes de informaciÃ³n necesarias.\n",
    "3. **Explorar y visualizar los datos** â€” Analizar y detectar patrones, relaciones o anomalÃ­as.\n",
    "4. **Preparar los datos** â€” Limpiar, transformar y dejar listos los datos para los algoritmos.\n",
    "5. **Seleccionar y entrenar un modelo** â€” Probar distintos modelos de *machine learning*.\n",
    "6. **Ajustar el modelo** â€” Optimizar los hiperparÃ¡metros y mejorar el rendimiento.\n",
    "7. **Presentar la soluciÃ³n** â€” Comunicar resultados y conclusiones de forma clara.\n",
    "8. **Desplegar, monitorear y mantener el sistema** â€” Implementar el modelo en producciÃ³n y mantenerlo actualizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener los Datos\n",
    "\n",
    "Cuando queremos experimentar/aprender sobre machine learning, lo mejor es usar datos reales, y no un conjunto de datos inventados que no se corresponden con la realidad. por suerte para nosotros, hay un montÃ³n de pÃ¡ginas, repositorios y proyetos de donde podremos conseguir conjuntos de datos reales y de una multitud de campos de conocimiento.\n",
    "\n",
    "Por ejemplo, dos portales muy populares donde podremos conseguir datos son:\n",
    "1. OpenML.org\n",
    "2. Kaggle.com\n",
    "\n",
    "Para este cuaderno y para aprender los conceptos que GerÃ³n explica en este capÃ­tulo del libro, vamos a usar un conjunto de datos que representa los precios de las viviendas de California, y que podemos conseguir del repositorio StatLib.\n",
    "\n",
    "Estos datos se basan en el censo que se hizo en California en 1990. No son los datos mas recientes pero para aprender los conceptos de este capitulo nos servirÃ¡n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "def load_housing_data():\n",
    "    # Define la ruta donde se guardarÃ¡ el archivo comprimido\n",
    "    tarball_path = Path(\"datasets/housing.tgz\")\n",
    "\n",
    "    # Verifica si el archivo ya existe\n",
    "    if not tarball_path.is_file():\n",
    "        # Crea el directorio 'datasets' si no existe\n",
    "        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # URL del archivo de datos en GitHub\n",
    "        url = \"https://github.com/ageron/data/raw/main/housing.tgz\"\n",
    "\n",
    "        # Descarga el archivo desde la URL y lo guarda en tarball_path\n",
    "        urllib.request.urlretrieve(url, tarball_path)\n",
    "\n",
    "        # Abre el archivo comprimido (.tgz)\n",
    "        with tarfile.open(tarball_path) as housing_tarball:\n",
    "          # Extrae todo el contenido en el directorio 'datasets'\n",
    "          housing_tarball.extractall(path=\"datasets\")\n",
    "\n",
    "    # Lee el archivo CSV y lo retorna como un DataFrame de pandas\n",
    "    return pd.read_csv(Path(\"datasets/housing/housing.csv\"))\n",
    "\n",
    "# Carga los datos de vivienda llamando a la funciÃ³n\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer vistazo a la estructura de los datos\n",
    "\n",
    "Antes de empezar, veamos quÃ© aspecto tienen los datos. Veamos con head() los primeros 5 registros o filas del dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada una de las filas representa un distrito, y vemos que hay 10 atributos:\n",
    "\n",
    "* **longitude** â€“ longitud geogrÃ¡fica del distrito  \n",
    "* **latitude** â€“ latitud geogrÃ¡fica del distrito  \n",
    "* **housing_median_age** â€“ edad mediana de las viviendas en el distrito  \n",
    "* **total_rooms** â€“ nÃºmero total de habitaciones en el distrito  \n",
    "* **total_bedrooms** â€“ nÃºmero total de dormitorios en el distrito  \n",
    "* **population** â€“ poblaciÃ³n total del distrito  \n",
    "* **households** â€“ nÃºmero total de hogares (familias) en el distrito  \n",
    "* **median_income** â€“ ingreso medio de los hogares en el distrito  \n",
    "* **median_house_value** â€“ valor mediano de las viviendas (variable objetivo)  \n",
    "* **ocean_proximity** â€“ categorÃ­a que indica la cercanÃ­a al ocÃ©ano\n",
    "\n",
    "El mÃ©todo info() es muy Ãºtil para obtener una rÃ¡pida descripciÃ³n de los datos, en particular el nÃºmero de filas, el tipo de cada uno de los atributos, y el nÃºmero de valores existentes (o no nulos):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos contiene 20,640 instancias, lo cual es relativamente pequeÃ±o segÃºn los estÃ¡ndares de machine learning, pero es adecuado para comenzar. Se observa que el atributo total_bedrooms tiene solo 20,433 valores no nulos, lo que significa que 207 distritos tienen este valor faltante, situaciÃ³n que deberÃ¡ abordarse posteriormente. Todos los atributos son numÃ©ricos excepto ocean_proximity, cuyo tipo es object, lo que indica que podrÃ­a contener cualquier tipo de objeto Python. Sin embargo, dado que los datos provienen de un archivo CSV, se puede confirmar que es un atributo de texto. Al examinar las primeras filas, se observa que los valores en la columna ocean_proximity son repetitivos, lo que sugiere que se trata de un atributo categÃ³rico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"ocean_proximity\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen EstadÃ­stico de Atributos NumÃ©ricos\n",
    "\n",
    "El mÃ©todo describe() proporciona un resumen de los atributos numÃ©ricos del conjunto de datos. Las filas count, mean, min y max son autoexplicativas, y es importante notar que los valores nulos son ignorados en el cÃ¡lculo (por ejemplo, el count de total_bedrooms es 20,433, no 20,640). La fila std muestra la desviaciÃ³n estÃ¡ndar, que mide quÃ© tan dispersos estÃ¡n los valores. Las filas 25%, 50% y 75% muestran los percentiles correspondientes: un percentil indica el valor por debajo del cual cae un determinado porcentaje de observaciones. Por ejemplo, el 25% de los distritos tienen un housing_median_age menor a 18, mientras que el 50% es menor a 29 y el 75% es menor a 37. Estos valores se conocen como el percentil 25 (o primer cuartil), la mediana, y el percentil 75 (o tercer cuartil), respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VisualizaciÃ³n con Histogramas\n",
    "Otra forma rÃ¡pida de familiarizarse con el tipo de datos con los que se estÃ¡ trabajando es graficar un histograma para cada atributo numÃ©rico. Un histograma muestra el nÃºmero de instancias (en el eje vertical) que tienen un rango de valores determinado (en el eje horizontal). Se puede graficar un atributo a la vez, o bien llamar al mÃ©todo hist() sobre todo el conjunto de datos, lo cual generarÃ¡ automÃ¡ticamente un histograma para cada atributo numÃ©rico, permitiendo una visualizaciÃ³n rÃ¡pida y completa de la distribuciÃ³n de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÃ³digo adicional â€“ cÃ³digo para guardar las figuras como PNGs de alta resoluciÃ³n\n",
    "\n",
    "# Define la ruta donde se guardarÃ¡n las imÃ¡genes\n",
    "IMAGES_PATH = Path() / \"images\" / \"end_to_end_project\"\n",
    "\n",
    "# Crea el directorio si no existe (parents=True crea directorios padres si es necesario)\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    # Construye la ruta completa del archivo con el ID y la extensiÃ³n\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "\n",
    "    # Si tight_layout estÃ¡ activado, ajusta automÃ¡ticamente el espaciado de la figura\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "\n",
    "    # Guarda la figura en la ruta especificada con el formato y resoluciÃ³n indicados\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CÃ³digo adicional â€“ las siguientes 5 lÃ­neas definen los tamaÃ±os de fuente predeterminados\n",
    "plt.rc('font', size=14)  # TamaÃ±o de fuente general\n",
    "plt.rc('axes', labelsize=14, titlesize=14)  # TamaÃ±o de etiquetas y tÃ­tulos de los ejes\n",
    "plt.rc('legend', fontsize=14)  # TamaÃ±o de fuente de la leyenda\n",
    "plt.rc('xtick', labelsize=10)  # TamaÃ±o de las etiquetas del eje X\n",
    "plt.rc('ytick', labelsize=10)  # TamaÃ±o de las etiquetas del eje Y\n",
    "\n",
    "# Crea histogramas para todos los atributos numÃ©ricos del dataset\n",
    "# bins=50: divide los datos en 50 intervalos\n",
    "# figsize=(12, 8): define el tamaÃ±o de la figura en pulgadas\n",
    "housing.hist(bins=50, figsize=(12, 8))\n",
    "\n",
    "# Guarda la figura (cÃ³digo adicional)\n",
    "save_fig(\"attribute_histogram_plots\")\n",
    "\n",
    "# Muestra la figura en pantalla\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota sobre el parÃ¡metro bins de la funcion hist()**\n",
    "\n",
    "Un histograma agrupa los valores en \"contenedores\" o \"intervalos\" (bins en inglÃ©s) para contar cuÃ¡ntas observaciones caen en cada rango.\n",
    "\n",
    "Por ejemplo, si tienes edades de personas entre 0 y 100 aÃ±os y usas bins=50, el histograma dividirÃ¡ ese rango en 50 intervalos iguales (0-2, 2-4, 4-6, etc.) y contarÃ¡ cuÃ¡ntas personas caen en cada intervalo.\n",
    "\n",
    "Cada barra del histograma representa uno de esos intervalos.\n",
    "\n",
    "* MÃ¡s bins = mÃ¡s detalle pero puede verse ruidoso\n",
    "* Menos bins = menos detalle pero se ven mejor las tendencias generales\n",
    "\n",
    "En el cÃ³digo anterior, bins=50 significa que cada atributo numÃ©rico se dividirÃ¡ en 50 rangos de valores para crear su histograma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AnÃ¡lisis de los Histogramas\n",
    "\n",
    "Al observar los histogramas, se identifican varios aspectos importantes del conjunto de datos.\n",
    "\n",
    "Primero, el atributo median income no estÃ¡ expresado en dÃ³lares estadounidenses, sino que ha sido escalado y limitado entre 0.5 (0.4999) y 15 (15.0001), donde los nÃºmeros representan aproximadamente decenas de miles de dÃ³lares (por ejemplo, 3 significa alrededor de $30,000). Trabajar con atributos preprocesados es comÃºn en machine learning, aunque es fundamental comprender cÃ³mo fueron procesados los datos.\n",
    "\n",
    "Tanto housing median age como median house value tambiÃ©n fueron limitados (capped).\n",
    "\n",
    "Esto Ãºltimo puede ser problemÃ¡tico ya que median house value es el atributo objetivo, y los algoritmos podrÃ­an aprender que los precios nunca superan ese lÃ­mite.\n",
    "\n",
    "AquÃ­, como nota, serÃ­a necesario consultar con el equipo cliente si necesitan predicciones precisas mÃ¡s allÃ¡ de $500,000. En ese caso, hay dos opciones:\n",
    "\n",
    "* Recopilar etiquetas correctas para los distritos cuyos valores fueron limitados\n",
    "* Eliminar esos distritos tanto del conjunto de entrenamiento como del de prueba.\n",
    "\n",
    "Los atributos tienen escalas muy diferentes, tema que se abordarÃ¡ posteriormente al explorar el escalado de caracterÃ­sticas.\n",
    "\n",
    "Finalmente, muchos histogramas presentan asimetrÃ­a positiva (skewed right), extendiÃ©ndose mÃ¡s hacia la derecha de la mediana que hacia la izquierda, lo cual puede dificultar que algunos algoritmos detecten patrones. Posteriormente se considerarÃ¡ transformar estos atributos para obtener distribuciones mÃ¡s simÃ©tricas y con forma de campana."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}