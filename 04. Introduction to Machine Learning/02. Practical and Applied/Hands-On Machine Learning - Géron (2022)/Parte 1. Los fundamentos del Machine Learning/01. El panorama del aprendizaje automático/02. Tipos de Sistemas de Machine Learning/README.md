# Tipos de Sistemas de Machine Learning

## ğŸ“Š ClasificaciÃ³n Principal

Los sistemas de ML se clasifican segÃºn **tres criterios principales**:

1. **SupervisiÃ³n humana**: supervised, unsupervised, semisupervised, reinforcement learning
2. **Aprendizaje incremental**: online vs batch
3. **Estrategia de generalizaciÃ³n**: instance-based vs model-based learning

---

## ğŸ·ï¸ Supervised vs Unsupervised

### ğŸ“ Aprendizaje Supervisado

Los datos de entrenamiento incluyen la soluciÃ³n denominada **"label"**.

<div align="center">
  <img src="./assets/Aprendizaje_supervisado.png" alt="Aprendizaje Supervisado" width="600"/>
  <p><em>Un buen ejemplo de aprendizaje supervisado es la clasificaciÃ³n del spam en el correo electrÃ³nico. El aprendizaje supervisado se caracteriza porque todo el conjunto de datos que usas para entrenar un modelo estÃ¡ etiquetado, cada muestra contiene informaciÃ³n sobre sÃ­ misma, para que el modelo pueda aprender.</em></p>
</div>

#### Tareas TÃ­picas

- **ClasificaciÃ³n** (como filtros de spam)
- **RegresiÃ³n** (como predecir precios de coches)

> âš ï¸ **Nota importante:** Algunos algoritmos de regresiÃ³n pueden usarse para clasificaciÃ³n y viceversa.

#### Algoritmos MÃ¡s Importantes

- **k-nearest neighbors**
- **Linear regression**
- **Logistic regression**
- **Support Vector Machines (SVMs)**
- **Decision trees and random forests**
- **Neural networks** (aunque algunas arquitecturas pueden ser no supervisadas o semisupervisadas)

---

### ğŸ” Aprendizaje No Supervisado (Unsupervised Learning)

En el aprendizaje no supervisado **no hay etiquetas**, los datos de entrenamiento no estÃ¡n etiquetados y el sistema intenta aprender **"sin un profesor"**.

#### ğŸ“¦ Clustering

- **K-means**
- **Hierarchical Cluster Analysis (HCA)**
- **Expectation Maximization**

#### ğŸ“Š VisualizaciÃ³n y ReducciÃ³n de Dimensionalidad

- **Principal Component Analysis (PCA)**
- **Kernel PCA**
- **Locally-Linear Embedding (LLE)**
- **t-Distributed Stochastic Neighbor Embedding (t-SNE)**

#### ğŸ”— Association Rule Learning

- **Apriori**
- **Eclat**

> ğŸ’¡ **Buena prÃ¡ctica:** Siempre es recomendable aplicar reducciÃ³n de dimensionalidad a los datos de entrenamiento sin perder demasiada informaciÃ³n.

---

### ğŸ¯ Aprendizaje Semisupervisado

Algunos algoritmos pueden trabajar con **datasets parcialmente etiquetados**, constituyendo el aprendizaje semisupervisado.

#### Ejemplo PrÃ¡ctico

**Google Photos** agrupa fotos por personas que aparecen en ellas y solicita al usuario que las etiquete.

#### ComposiciÃ³n

La mayorÃ­a de algoritmos semisupervisados son **combinaciones de algoritmos no supervisados y supervisados**.

#### Deep Belief Networks (DBNs)

Un caso especÃ­fico son las **Deep Belief Networks (DBNs)**, que se basan en componentes no supervisados llamados **Restricted Boltzmann Machines (RBMs)** apilados.

**Proceso de entrenamiento:**
1. Los RBMs se entrenan secuencialmente de manera no supervisada
2. Todo el sistema se ajusta finamente (fine-tuned) utilizando tÃ©cnicas de aprendizaje supervisado

---

### ğŸ¤– Aprendizaje por Refuerzo (Reinforcement Learning)

En el aprendizaje por refuerzo, el sistema de aprendizaje se denomina **agente** y puede:

- ğŸ‘ï¸ Observar el entorno
- âš¡ Seleccionar y ejecutar acciones
- ğŸ Obtener recompensas a cambio (o penalizaciones en forma de recompensas negativas)

#### Policy

El agente debe aprender por sÃ­ mismo cuÃ¡l es la mejor estrategia, llamada **policy**, para obtener la mayor recompensa a lo largo del tiempo.

---

## ğŸ”„ Batch and Online Learning

### ğŸ“‹ Criterio de ClasificaciÃ³n

Otro criterio para clasificar los sistemas de ML es si el sistema puede aprender incrementalmente desde el flujo (**stream**) de datos de entrada o no.

Esta distinciÃ³n establece la diferencia entre:
- **Aprendizaje online**: El modelo puede actualizarse continuamente con nuevos datos
- **Aprendizaje batch**: Requiere entrenar desde cero con todo el conjunto de datos disponible

---

### ğŸ“¦ Batch Learning (Aprendizaje por Lotes)

En el batch learning, el sistema **no puede aprender incrementalmente** y debe ser reentrenado utilizando todos los datos disponibles.

#### CaracterÃ­sticas

- Se realiza **offline** porque requiere mucho tiempo y recursos computacionales
- Por esta razÃ³n se denomina **offline training**
- El proceso puede automatizarse (entrenar, evaluar, lanzar)

#### Limitaciones

> âš ï¸ **Problema principal:** El entrenamiento sobre nuevos datos junto con los antiguos puede durar horas, lo que representa una limitaciÃ³n significativa cuando se necesita actualizar el modelo con frecuencia.

---

### ğŸ”„ Online Learning

En el online learning, el modelo se entrena de manera **incremental** alimentÃ¡ndolo con instancias de datos secuenciales individualmente o en pequeÃ±os grupos llamados **mini-batches**.

#### Ventajas

- âš¡ Cada paso de aprendizaje es **rÃ¡pido y econÃ³mico**
- ğŸ” El sistema aprende sobre la marcha con nuevos datos segÃºn van llegando
- ğŸ’» Es una buena opciÃ³n cuando se tienen **recursos limitados**

#### Out-of-Core Learning

Los algoritmos de aprendizaje online tambiÃ©n pueden usarse para entrenar sistemas sobre **grandes datasets que no caben en la memoria** de una mÃ¡quina, proceso conocido como **out-of-core learning**.

#### Learning Rate

Un parÃ¡metro importante es el **learning rate**, que determina quÃ© tan rÃ¡pido se adapta el sistema a los cambios.

#### âš ï¸ DesafÃ­os

Uno de los principales retos es evitar que el rendimiento decaiga cuando entran **datos de mala calidad** al sistema.

> ğŸ’¡ **SoluciÃ³n:** Para minimizar este riesgo, es necesario monitorizar tanto el sistema como su entrada de datos.

---

## ğŸ¯ Instance-Based vs Model-Based Learning

### Objetivo de la GeneralizaciÃ³n

Otra manera de categorizar sistemas de ML es segÃºn **cÃ³mo generalizan**, ya que el objetivo final es **predecir correctamente nuevas instancias**.

Existen **dos enfoques principales** de generalizaciÃ³n:
- **Instance-based learning**
- **Model-based learning**

Cada uno con estrategias diferentes para hacer predicciones sobre datos no vistos previamente.

---

### ğŸ’¾ Instance-Based Learning

Posiblemente la forma mÃ¡s trivial de aprendizaje es **aprender de memoria**.

#### Ejemplo: ClasificaciÃ³n de Spam

Por ejemplo, clasificar emails como spam cuando son idÃ©nticos a correos ya etiquetados como spam. No es la peor soluciÃ³n, pero ciertamente no es la mejor.

#### Medida de Similitud

Se puede usar una **medida de similitud** para etiquetar correos parecidos al spam.

Una forma bÃ¡sica de similitud en el caso del spam es **contar el nÃºmero de palabras que tienen en comÃºn**.

#### DefiniciÃ³n

> ğŸ“Œ **Instance-based learning:** El sistema aprende los ejemplos de memoria y luego generaliza a nuevos casos usando medidas de similitud.

---

### ğŸ”¬ Model-Based Learning

Otra forma de generalizar a partir de un conjunto de ejemplos es **construir un modelo** de esos ejemplos y luego usar dicho modelo para hacer predicciones.

#### Ejemplo: SatisfacciÃ³n de Vida vs GDP

Si descargamos datos de GDP per cÃ¡pita de paÃ­ses y el Ã­ndice de satisfacciÃ³n de vida:

1. Hacemos un grÃ¡fico
2. Observamos una especie de relaciÃ³n lineal
3. Decidimos modelar la satisfacciÃ³n de vida como una funciÃ³n lineal del GDP per cÃ¡pita

#### Model Selection

> ğŸ“Š **Model Selection:** Hemos seleccionado un modelo lineal de la satisfacciÃ³n de vida con un solo atributo, el GDP per cÃ¡pita.

#### SelecciÃ³n de ParÃ¡metros

Antes de usar el modelo, debemos seleccionar algunos **parÃ¡metros** para la funciÃ³n lineal.

Para elegir estos parÃ¡metros, debemos definir una **medida de rendimiento**.

#### Funciones de EvaluaciÃ³n

Podemos definir:

- **Utility function** (o fitness function): mide quÃ© tan **bueno** es el modelo
- **FunciÃ³n de costo**: mide cuÃ¡n **malo** es

#### RegresiÃ³n Lineal

Para problemas de **regresiÃ³n lineal**, se usa tÃ­picamente una funciÃ³n de costo que mide la distancia entre:
- La predicciÃ³n del modelo lineal
- Las muestras de ejemplo

> ğŸ¯ **Objetivo:** Minimizar esta distancia, y aquÃ­ es donde el **algoritmo de regresiÃ³n lineal** entra en escena.
